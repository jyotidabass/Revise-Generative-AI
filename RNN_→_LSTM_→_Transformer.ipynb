{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4hIiXqsCIiz3ifrtPBVjm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/Revise-Generative-AI/blob/main/RNN_%E2%86%92_LSTM_%E2%86%92_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Understanding Next Word Prediction**"
      ],
      "metadata": {
        "id": "eRcHgZemKBAC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_MUaLVuBxzS",
        "outputId": "99b25a5f-a9e5-4e84-ea6e-4addb96732f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word: coffee\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "sentence = \"I love drinking hot\"\n",
        "\n",
        "next_word_options = {\n",
        "    \"coffee\": 0.6,\n",
        "    \"tea\": 0.3,\n",
        "    \"soup\": 0.1\n",
        "}\n",
        "\n",
        "prediction = max(next_word_options, key=next_word_options.get)\n",
        "\n",
        "print(\"Predicted next word:\", prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Why Early Models Struggled — RNN**"
      ],
      "metadata": {
        "id": "7HIz2BQpKYq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulating RNN memory fading\n",
        "\n",
        "sentence = [\"I\", \"live\", \"in\", \"New\", \"York\"]\n",
        "\n",
        "hidden_state = 0\n",
        "\n",
        "for word in sentence:\n",
        "    hidden_state = hidden_state * 0.5 + 1\n",
        "    print(\"Processing:\", word, \"| Hidden state:\", hidden_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TOsCpd1C15j",
        "outputId": "4b9c3f03-8547-4f7f-9d9a-1b50fb4f2751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: I | Hidden state: 1.0\n",
            "Processing: live | Hidden state: 1.5\n",
            "Processing: in | Hidden state: 1.75\n",
            "Processing: New | Hidden state: 1.875\n",
            "Processing: York | Hidden state: 1.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM — Solving the Memory Problem**"
      ],
      "metadata": {
        "id": "UgOSLvd6Kl56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulating LSTM-style controlled memory\n",
        "\n",
        "memory = 0\n",
        "\n",
        "forget_gate = 0.8\n",
        "input_gate = 0.6\n",
        "\n",
        "new_information = 5\n",
        "\n",
        "memory = memory * forget_gate + new_information * input_gate\n",
        "\n",
        "print(\"Updated memory:\", memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk8yNrsGEC99",
        "outputId": "9698ea32-827a-4a64-eb11-c8c60eefe793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated memory: 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Breakthrough — Transformers**"
      ],
      "metadata": {
        "id": "Sc9Y0_lGKw6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simplified word meaning vectors\n",
        "bank_financial = np.array([1, 0])\n",
        "bank_river = np.array([0, 1])\n",
        "\n",
        "# Context leaning towards finance\n",
        "query = np.array([1, 0])\n",
        "\n",
        "score_financial = np.dot(bank_financial, query)\n",
        "score_river = np.dot(bank_river, query)\n",
        "\n",
        "print(\"Attention score (financial bank):\", score_financial)\n",
        "print(\"Attention score (river bank):\", score_river)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj0r5IEtFVmc",
        "outputId": "beb242cf-d103-4ab5-8854-39fd1981c80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention score (financial bank): 1\n",
            "Attention score (river bank): 0\n"
          ]
        }
      ]
    }
  ]
}